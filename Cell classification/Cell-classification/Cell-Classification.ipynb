{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Classification project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parasitized', 'uninfected']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_Train_Path = Path(r\"cell_images\\train\")\n",
    "Main_Test_Path = Path(r\"cell_images\\test\")\n",
    "os.listdir(Main_Train_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cell_images\\\\train\\\\parasitized\\\\C100P61ThinF_IMG_20150918_144104_cell_162.png', 'cell_images\\\\train\\\\parasitized\\\\C100P61ThinF_IMG_20150918_144104_cell_163.png', 'cell_images\\\\train\\\\parasitized\\\\C100P61ThinF_IMG_20150918_144104_cell_164.png', 'cell_images\\\\train\\\\parasitized\\\\C100P61ThinF_IMG_20150918_144104_cell_165.png', 'cell_images\\\\train\\\\parasitized\\\\C100P61ThinF_IMG_20150918_144104_cell_166.png']\n"
     ]
    }
   ],
   "source": [
    "Train_PNG_Path = list(Main_Train_Path.glob(r\"*/*.png\"))\n",
    "Test_PNG_Path = list(Main_Test_Path.glob(r\"*/*.png\"))\n",
    "Train_PNG_Path = [str(path) for path in Train_PNG_Path]\n",
    "Test_PNG_Path = [str(path) for path in Test_PNG_Path]\n",
    "print(Train_PNG_Path[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Parasitized:  12479\n",
      "Train Uninfected:  12479\n"
     ]
    }
   ],
   "source": [
    "Train_PNG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Train_PNG_Path))\n",
    "print(\"Train Parasitized: \",Train_PNG_Labels.count(\"parasitized\"))\n",
    "print(\"Train Uninfected: \",Train_PNG_Labels.count(\"uninfected\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Parasitized:  1300\n",
      "Test Uninfected:  1300\n"
     ]
    }
   ],
   "source": [
    "Test_PNG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Test_PNG_Path))\n",
    "print(\"Test Parasitized: \",Test_PNG_Labels.count(\"parasitized\"))\n",
    "print(\"Test Uninfected: \",Test_PNG_Labels.count(\"uninfected\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels to integers: 'parasitized' -> 0, 'uninfected' -> 1\n",
    "label_map = {'parasitized': 0, 'uninfected': 1}\n",
    "Train_PNG_Labels = [label_map[label] for label in Train_PNG_Labels]\n",
    "Test_PNG_Labels = [label_map[label] for label in Test_PNG_Labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [128, 128])  # Resize to a fixed size\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a TensorFlow dataset\n",
    "def create_dataset(paths, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    dataset = dataset.map(lambda x, y: preprocess_image(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=len(paths))\n",
    "    dataset = dataset.batch(batch_size=32)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24958\n",
      "After spliting Training data to Training & Validation:\n",
      "Train data:  19966  Validation data:  4992\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "print(len(Train_PNG_Labels))\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(Train_PNG_Path, Train_PNG_Labels, test_size=0.2, random_state=42)\n",
    "print(\"After spliting Training data to Training & Validation:\")\n",
    "print(\"Train data: \", len(train_paths), \" Validation data: \" , len(val_paths))\n",
    "train_dataset = create_dataset(train_paths, train_labels)\n",
    "val_dataset = create_dataset(val_paths, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m figure,axis \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m12\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(axis\u001b[38;5;241m.\u001b[39mflat):\n\u001b[0;32m      4\u001b[0m     IMG \u001b[38;5;241m=\u001b[39m imread(Train_PNG_Path[i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(12,12))\n",
    "\n",
    "for i,ax in enumerate(axis.flat):\n",
    "    IMG = imread(Train_PNG_Path[i])\n",
    "    ax.set_xlabel(IMG.shape)\n",
    "    ax.set_ylabel(IMG.size)\n",
    "    ax.set_title(Train_PNG_Labels[i])\n",
    "    ax.imshow(IMG,cmap=\"Greys_r\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3211392   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3304769 (12.61 MB)\n",
      "Trainable params: 3304769 (12.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#using Keras Sequential model and Dense Layer with a ReLU activation to construct the three layer network described above.\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Single output for binary classification\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 273s 426ms/step - loss: 0.3149 - accuracy: 0.8641 - val_loss: 0.1953 - val_accuracy: 0.9379\n",
      "Epoch 2/10\n",
      "624/624 [==============================] - 243s 377ms/step - loss: 0.1605 - accuracy: 0.9470 - val_loss: 0.1476 - val_accuracy: 0.9539\n",
      "Epoch 3/10\n",
      "624/624 [==============================] - 252s 391ms/step - loss: 0.1308 - accuracy: 0.9565 - val_loss: 0.1376 - val_accuracy: 0.9551\n",
      "Epoch 4/10\n",
      "624/624 [==============================] - 255s 395ms/step - loss: 0.1154 - accuracy: 0.9608 - val_loss: 0.1724 - val_accuracy: 0.9437\n",
      "Epoch 5/10\n",
      "624/624 [==============================] - 253s 392ms/step - loss: 0.1060 - accuracy: 0.9632 - val_loss: 0.1326 - val_accuracy: 0.9591\n",
      "Epoch 6/10\n",
      "624/624 [==============================] - 257s 398ms/step - loss: 0.0857 - accuracy: 0.9694 - val_loss: 0.1450 - val_accuracy: 0.9583\n",
      "Epoch 7/10\n",
      "624/624 [==============================] - 260s 401ms/step - loss: 0.0703 - accuracy: 0.9745 - val_loss: 0.1626 - val_accuracy: 0.9591\n",
      "Epoch 8/10\n",
      "624/624 [==============================] - 240s 368ms/step - loss: 0.0565 - accuracy: 0.9792 - val_loss: 0.1816 - val_accuracy: 0.9553\n",
      "Epoch 9/10\n",
      "624/624 [==============================] - 263s 407ms/step - loss: 0.0413 - accuracy: 0.9857 - val_loss: 0.1967 - val_accuracy: 0.9495\n",
      "Epoch 10/10\n",
      "624/624 [==============================] - 245s 378ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.2506 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26decc81590>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 12s 94ms/step\n",
      "[0.9997219]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = create_dataset(Test_PNG_Path,Test_PNG_Labels)\n",
    "predictions = model.predict(test_dataset)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 8s 91ms/step - loss: 0.2628 - accuracy: 0.9423\n",
      "Test loss, Test Accuracy:  [0.2627905011177063, 0.942307710647583]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "print(\"Test loss, Test Accuracy: \", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
